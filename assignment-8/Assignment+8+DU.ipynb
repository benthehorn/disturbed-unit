{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold, cross_val_predict, train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import classification_report\n",
    "import scipy\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1.1\n",
    "#Accuracy could be described as how close we are to the centre of a target, where as Precision would\n",
    "#describe how well grouped our results are. So we could have low accuracy and high presicion, and vice versa,\n",
    "#but still have an inaccurate model. We need high precision and accuracy, if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1.2\n",
    "# Precision and Recall are the measure of which instances are relevant. Precision describes the relevant instances\n",
    "# from the whole set, where as Recall describes the relevant instances from only the relevant instances.\n",
    "# F1 = 2 * (precision * recall)/(precision + recall) closer to 1 is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        mal       1.00      0.09      0.17        11\n",
      "        ben       0.82      1.00      0.90        46\n",
      "\n",
      "avg / total       0.86      0.82      0.76        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        mal       0.79      0.94      0.86        35\n",
      "        ben       0.87      0.59      0.70        22\n",
      "\n",
      "avg / total       0.82      0.81      0.80        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        mal       0.85      0.97      0.91        36\n",
      "        ben       0.94      0.71      0.81        21\n",
      "\n",
      "avg / total       0.88      0.88      0.87        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        mal       0.96      0.90      0.93        29\n",
      "        ben       0.90      0.96      0.93        28\n",
      "\n",
      "avg / total       0.93      0.93      0.93        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        mal       0.93      0.93      0.93        29\n",
      "        ben       0.93      0.93      0.93        28\n",
      "\n",
      "avg / total       0.93      0.93      0.93        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        mal       0.85      1.00      0.92        45\n",
      "        ben       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.88      0.86      0.83        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        mal       0.89      1.00      0.94        41\n",
      "        ben       1.00      0.69      0.81        16\n",
      "\n",
      "avg / total       0.92      0.91      0.91        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        mal       0.86      0.98      0.91        44\n",
      "        ben       0.86      0.46      0.60        13\n",
      "\n",
      "avg / total       0.86      0.86      0.84        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        mal       0.86      1.00      0.93        44\n",
      "        ben       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.89      0.88      0.86        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        mal       0.88      1.00      0.93        43\n",
      "        ben       1.00      0.54      0.70        13\n",
      "\n",
      "avg / total       0.91      0.89      0.88        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "dFrame = pd.read_csv('cancerData.csv', sep=',')\n",
    "\n",
    "logModel = linear_model.LogisticRegression()\n",
    "cols = ['radius', 'perimeter', 'concavity']\n",
    "X = dFrame[cols].values.reshape(-1, len(cols))\n",
    "Y = dFrame['diagnosis']\n",
    "stats = ['mal', 'ben']\n",
    "folds = KFold(n_splits=10)\n",
    "for train, test in folds.split(X,Y):\n",
    "    X_Train, X_Test = X[train], X[test]\n",
    "    Y_Train, Y_Test = Y[train], Y[test]\n",
    "    \n",
    "\n",
    "    logModel.fit(X_Train, Y_Train)\n",
    "\n",
    "    pred = cross_val_predict(logModel, X_Test, Y_Test, cv=10)\n",
    "    print(classification_report(Y_Test, pred, target_names=stats))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Gender</th>\n",
       "      <th>FSIQ</th>\n",
       "      <th>VIQ</th>\n",
       "      <th>PIQ</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>MRI_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>124</td>\n",
       "      <td>118</td>\n",
       "      <td>64.5</td>\n",
       "      <td>816932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>140</td>\n",
       "      <td>150</td>\n",
       "      <td>124</td>\n",
       "      <td>.</td>\n",
       "      <td>72.5</td>\n",
       "      <td>1001121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>139</td>\n",
       "      <td>123</td>\n",
       "      <td>150</td>\n",
       "      <td>143</td>\n",
       "      <td>73.3</td>\n",
       "      <td>1038437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>133</td>\n",
       "      <td>129</td>\n",
       "      <td>128</td>\n",
       "      <td>172</td>\n",
       "      <td>68.8</td>\n",
       "      <td>965353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>137</td>\n",
       "      <td>132</td>\n",
       "      <td>134</td>\n",
       "      <td>147</td>\n",
       "      <td>65.0</td>\n",
       "      <td>951545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Gender  FSIQ  VIQ  PIQ Weight Height  MRI_Count\n",
       "0           1  Female   133  132  124    118   64.5     816932\n",
       "1           2    Male   140  150  124      .   72.5    1001121\n",
       "2           3    Male   139  123  150    143   73.3    1038437\n",
       "3           4    Male   133  129  128    172   68.8     965353\n",
       "4           5  Female   137  132  134    147   65.0     951545"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2\n",
    "\n",
    "bFrame = pd.read_csv('brain_size.csv', sep=';')\n",
    "\n",
    "heights = bFrame.dropna(subset=['Height'], how='all')\n",
    "heights.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.1\n",
    "# The t-test is an inference test. The result tells us if we can infer anything from our results, by comparing two sets\n",
    "# of means, and telling us the significance of the difference. P value is the probablity that our results happened by c\n",
    "# chance, in percent. Low values are good, they show that the results weren't just achieved by chance, but are relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-3.8682665640568583, pvalue=0.00041658142370520256)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2.2\n",
    "heights = heights[heights['Height'] !='.']\n",
    "h_data = heights['Height'].values.astype(float)\n",
    "\n",
    "stats.ttest_1samp(h_data, 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The very low P-value tells us that our results weren't just arrived at by chance. \n",
    "# The t-test score of 3 shows that there is a large difference between the two groups, so\n",
    "# we can say that the height of the people in the sample set is not similar to the population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=0.1964197529935458, pvalue=0.84532834985133909)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2.3\n",
    "stats.ttest_1samp(h_data, 68.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The opposite is true here. We have a high p-value, indicating a high percent of probability, as well as a low\n",
    "# t-test score. So the sample does match the populations height very closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.890625\n",
      "Accuracy :  0.90234375\n",
      "Accuracy :  0.626953125\n",
      "Accuracy :  0.86328125\n",
      "Accuracy :  0.640625\n",
      "Accuracy :  0.609375\n",
      "Accuracy :  0.6171875\n",
      "Accuracy :  0.611328125\n",
      "Accuracy :  0.611328125\n",
      "Accuracy :  0.824561403509\n",
      "Mean Accuracy :  0.719760827851\n"
     ]
    }
   ],
   "source": [
    "# Part 3\n",
    "from sklearn.linear_model import Perceptron\n",
    "logModel = Perceptron()\n",
    "cols = ['radius', 'perimeter', 'concavity']\n",
    "X = dFrame[cols].values.reshape(-1, len(cols))\n",
    "Y = dFrame['diagnosis']\n",
    "stats = ['mal', 'ben']\n",
    "accuracies = []\n",
    "folds = KFold(n_splits=10)\n",
    "for train, test in folds.split(X,Y):\n",
    "    X_Train, X_Test = X[train], X[test]\n",
    "    Y_Train, Y_Test = Y[train], Y[test]\n",
    "    \n",
    "\n",
    "    logModel.fit(X_Train, Y_Train)\n",
    "    accuracies.append(logModel.score(X_Train, Y_Train))\n",
    "    print('Accuracy : ', logModel.score(X_Train, Y_Train))\n",
    "    \n",
    "print('Mean Accuracy : ', np.mean(accuracies))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
